{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "test_binary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzHCR0JfI8VY"
      },
      "source": [
        "#!pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ZglR8zI9ON"
      },
      "source": [
        "#!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a80IPFtiYlm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36758d9d-28d2-4aa9-8f0c-6556782a4853"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras import layers\n",
        "print(tf.__version__)\n",
        "import time\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.patches as mpatches\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import random\n",
        "import itertools\n",
        "from matplotlib.patches import Ellipse\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.optimize import curve_fit\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow_addons as tfa\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS-7roL_wCqH"
      },
      "source": [
        "size = 25"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-_OAtkAwCqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f0c340-f2f1-417c-aef5-96730de88813"
      },
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
        "tf.compat.v1.Session(config=config)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7fa8330386d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1qIg7JnwCqL"
      },
      "source": [
        "![title](擷取.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I54349RwCqM"
      },
      "source": [
        "def gernate_data(n, nu, seed, range_, multi, size):\n",
        "    ## normal\n",
        "    np.random.seed(seed=seed)\n",
        "    y_train = np.ones((int(n*(1-nu)),))\n",
        "    mean = np.random.uniform(-5, 5, size)\n",
        "    cov_  = np.random.uniform(0, 1, (size, size))* 3\n",
        "    cov = np.dot(cov_.T,cov_)\n",
        "    x_train = np.random.multivariate_normal(mean, cov, (int(n*(1-nu))))\n",
        "    x_train = x_train.astype('float32')\n",
        "\n",
        "    \n",
        "    \n",
        "    np.random.seed(seed=seed)\n",
        "    x_trains_ = None ## normal + outlier\n",
        "    for i in range(multi):\n",
        "        mean = np.random.uniform(-range_, range_, size)\n",
        "        cov_ = np.random.randn(size, size)\n",
        "        cov = np.dot(cov_.T,cov_)\n",
        "        x_train_ = np.random.multivariate_normal(mean, cov, (int(n*nu/multi)), check_valid  = 'raise')\n",
        "        try:\n",
        "            x_trains_ = np.vstack((x_trains_, x_train_))\n",
        "        except:\n",
        "            x_trains_ = x_train_\n",
        "    ## 畫圖\n",
        "    '''fig = plt.figure()\n",
        "    ax = Axes3D(fig)\n",
        "    ax.scatter(x_train[:, 0], x_train[:, 1],x_train[:, 2], s=0.9, label = 'normal')\n",
        "    ax.scatter(x_trains_[:,0], x_trains_[:,1], x_trains_[:,2], s=0.9, label = 'outlier')\n",
        "    plt.legend()\n",
        "    plt.title('normal + outlier')\n",
        "    plt.show()'''\n",
        "\n",
        "    y_trains_ = np.zeros(((len(x_trains_),)))\n",
        "    x_train_mix = np.vstack((x_trains_, x_train)).astype('float32')\n",
        "    y_train_mix = np.hstack((y_trains_, y_train)).astype('float32')\n",
        "    \n",
        "    return x_train_mix, y_train_mix"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1hkHlXiQ1io"
      },
      "source": [
        "## 參數設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW-G91MqQ1ip"
      },
      "source": [
        "\n",
        "z_dim = 5\n",
        "h_dim = [10, 5]\n",
        "regular = 1e-5\n",
        "max_lr = 1e-6\n",
        "base_lr = 1e-5\n",
        "\n",
        "\n",
        "n_epochs = 1000\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr = base_lr)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX69gKA8VgAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c352e49a-57f4-4700-c79e-479853316116"
      },
      "source": [
        "def make_ae_model():\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(size,), name='inputs')\n",
        "\n",
        "    x = tf.keras.layers.Dense(h_dim[0], activation='relu', use_bias=True)(inputs)\n",
        "    x = tf.keras.layers.Dense(h_dim[1], activation='linear', use_bias=False, name = 'hidden')(x)\n",
        "    x = tf.keras.layers.Dense(h_dim[0], activation='relu', use_bias=True)(x)\n",
        "    x = tf.keras.layers.Dense(size, activation='linear', use_bias=True)(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "    return model\n",
        "\n",
        "ae_model = make_ae_model()\n",
        "ae_model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 25)]              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                260       \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 5)                 50        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 25)                275       \n",
            "=================================================================\n",
            "Total params: 645\n",
            "Trainable params: 645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ac2_sMuwCqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7113df-6991-4dbe-ebe7-0cd90cdfc712"
      },
      "source": [
        "def make_model(model):\n",
        "    \n",
        "    model.trainable = True\n",
        "    x = model.get_layer('hidden').output\n",
        "    \n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model_out = tf.keras.Model(inputs = model.input, outputs = outputs)\n",
        "    \n",
        "    return model_out\n",
        "\n",
        "model = make_model(ae_model)\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 25)]              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                260       \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 5)                 50        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 316\n",
            "Trainable params: 316\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98SbxZKwwCqn"
      },
      "source": [
        "## Train SA-SVDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTUIw_xFmg2I"
      },
      "source": [
        "class train_classfication():\n",
        "    \n",
        "    def __init__(self , binary_model, train_dataset, nu ):\n",
        "        \n",
        "        self.nu = nu\n",
        "        self.binary_model = binary_model\n",
        "        self.optimizer = tf.keras.optimizers.Adam(lr = 1e-2, epsilon = 1e-6)\n",
        "        self.train_dataset = train_dataset\n",
        "\n",
        "    def loss(self, batch_x, batch_y):\n",
        "        \n",
        "        fl = tfa.losses.SigmoidFocalCrossEntropy()\n",
        "        end_loss = fl(y_true = batch_y, y_pred = batch_x)\n",
        "\n",
        "        return end_loss\n",
        "\n",
        "    @tf.function\n",
        "    def train_model(self, batch_x, batch_y):\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self.binary_model(batch_x, training=True)\n",
        "            output = tf.squeeze(output)\n",
        "            output_loss = self.loss(output, batch_y)\n",
        "\n",
        "        grads = tape.gradient(output_loss, self.binary_model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.binary_model.trainable_variables))\n",
        "\n",
        "        return output_loss\n",
        "    \n",
        "    def train( self, lr_milestone = 15):\n",
        "        \n",
        "        \n",
        "        pre_loss = np.inf\n",
        "        loss = 0.\n",
        "        #while abs(loss - pre_loss) > 1e-6:\n",
        "        for i in range(100):\n",
        "            epoch_ae_loss_avg = tf.metrics.Mean()\n",
        "\n",
        "            for batch, (batch_x, batch_y) in enumerate(train_dataset):\n",
        "\n",
        "                ae_loss = self.train_model(batch_x, batch_y)\n",
        "                epoch_ae_loss_avg(ae_loss)\n",
        "            #loss_list.append(epoch_ae_loss_avg.result())\n",
        "        \n",
        "        self.binary_model.save_weights('model_{}'.format(\n",
        "            self.nu))\n",
        "        \n",
        "    def score(self, data):\n",
        "        self.binary_model.load_weights('model_{}' .format(\n",
        "            self.nu))\n",
        "        output = self.binary_model(data, training = False)\n",
        "        return output\n",
        "    \n",
        "    def train_result(self, x_novali, y_novali, show_img = False):\n",
        "        \n",
        "        test_auc = 0.\n",
        "        confusionmatrix = 0.\n",
        "        if show_img:\n",
        "            scores = self.score(x_novali).numpy()\n",
        "            test_auc = self.result(scores, y_novali)\n",
        "\n",
        "            \n",
        "            \n",
        "        return radius_end, test_auc, confusionmatrix\n",
        "    \n",
        "    def result(self, scores, y_test):\n",
        "        \n",
        "        y_true = y_test\n",
        "        test_auc = roc_auc_score(y_true, scores)\n",
        "\n",
        "        return test_auc \n",
        "    \n",
        "    def test_result(self, x_test, y_test):\n",
        "        \n",
        "        scores = self.score(x_test).numpy()\n",
        "        test_auc = self.result(scores, y_test)\n",
        "\n",
        "        return test_auc"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3O8U_48UOyh"
      },
      "source": [
        "nu = 0.1\n",
        "x_train_mix, y_train_mix = gernate_data(6000, nu, 16, range_ = 10, multi = 15, size = size)\n",
        "x_test_mix, y_test_mix = gernate_data(10000, nu, 16,range_ = 10, multi = 15, size = size)\n",
        "n_samples = len(x_train_mix)\n",
        "\n",
        "\n",
        "batch_size = 2000\n",
        "train_buf = x_train_mix.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_mix, y_train_mix))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
        "train_dataset = train_dataset.batch(batch_size)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xru9UmeCURMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d522a0-b4f4-403a-cccc-e396407bae4e"
      },
      "source": [
        "result = np.zeros((25, 3))\n",
        "warm_up_n_epochs = 10\n",
        "for i in range(25):\n",
        "    pre_time = time.time()\n",
        "    ae_model = make_ae_model()\n",
        "    ae_model.compile(optimizer=\"Adam\", loss=\"mse\")\n",
        "    ae_model.fit(x_train_mix, x_train_mix, epochs = 30, verbose = 0)\n",
        "    ## 訓練 SVDD\n",
        "    binary_model = make_model(ae_model)\n",
        "    binary = train_classfication(binary_model, train_dataset, nu)\n",
        "    binary.train(x_train_mix)\n",
        "    auc  = binary.test_result(x_test_mix, y_test_mix)\n",
        "    train_time = time.time() - pre_time\n",
        "    print('epoch = ', i, 'auc = ', auc)\n",
        "    result[i,0] = i\n",
        "    result[i,1] = auc\n",
        "    result[i,2] = train_time"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch =  0 auc =  0.924159034792368\n",
            "epoch =  1 auc =  0.952507519640853\n",
            "epoch =  2 auc =  0.9361880471380472\n",
            "epoch =  3 auc =  0.9396383277216611\n",
            "epoch =  4 auc =  0.9435518518518519\n",
            "epoch =  5 auc =  0.9403551066217732\n",
            "epoch =  6 auc =  0.9434894500561168\n",
            "epoch =  7 auc =  0.9311827721661056\n",
            "epoch =  8 auc =  0.8976104377104377\n",
            "epoch =  9 auc =  0.933331088664422\n",
            "epoch =  10 auc =  0.9411315375982043\n",
            "epoch =  11 auc =  0.9573205387205387\n",
            "epoch =  12 auc =  0.9271482042648709\n",
            "epoch =  13 auc =  0.9220765432098766\n",
            "epoch =  14 auc =  0.9329731762065095\n",
            "epoch =  15 auc =  0.9452910213243548\n",
            "epoch =  16 auc =  0.9439716049382717\n",
            "epoch =  17 auc =  0.9674991021324354\n",
            "epoch =  18 auc =  0.9616514029180696\n",
            "epoch =  19 auc =  0.9474950056116722\n",
            "epoch =  20 auc =  0.9129679573512907\n",
            "epoch =  21 auc =  0.93339898989899\n",
            "epoch =  22 auc =  0.9534141414141415\n",
            "epoch =  23 auc =  0.9435142536475869\n",
            "epoch =  24 auc =  0.9345864197530864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3omq_uKy3CHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3510f47-654d-4919-e372-4001559e23b1"
      },
      "source": [
        "np.mean(result, 0)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.        ,  0.93865814, 14.94084741])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi1LsN8c8VJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4c544f-ba33-4f51-fcc0-267e660cb03a"
      },
      "source": [
        "np.std(result, 0)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.21110255, 0.01480397, 0.26979742])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYsnmBBNYNkd"
      },
      "source": [
        "nu = 0.2\n",
        "x_train_mix, y_train_mix = gernate_data(6000, nu, 16, range_ = 10, multi = 15, size = size)\n",
        "x_test_mix, y_test_mix = gernate_data(10000, nu, 16,range_ = 10, multi = 15, size = size)\n",
        "n_samples = len(x_train_mix)\n",
        "\n",
        "\n",
        "batch_size = 2000\n",
        "train_buf = x_train_mix.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_mix, y_train_mix))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
        "train_dataset = train_dataset.batch(batch_size)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swp-tcXAAaiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c11b48-3d39-4990-ffc6-f0f8d73af12a"
      },
      "source": [
        "result = np.zeros((25, 3))\n",
        "warm_up_n_epochs = 10\n",
        "for i in range(25):\n",
        "    pre_time = time.time()\n",
        "    ae_model = make_ae_model()\n",
        "    ae_model.compile(optimizer=\"Adam\", loss=\"mse\")\n",
        "    ae_model.fit(x_train_mix, x_train_mix, epochs = 30, verbose = 0)\n",
        "    ## 訓練 SVDD\n",
        "    binary_model = make_model(ae_model)\n",
        "    binary = train_classfication(binary_model, train_dataset, nu)\n",
        "    binary.train(x_train_mix)\n",
        "    auc  = binary.test_result(x_test_mix, y_test_mix)\n",
        "    train_time = time.time() - pre_time\n",
        "    print('epoch = ', i, 'auc = ', auc)\n",
        "    result[i,0] = i\n",
        "    result[i,1] = auc\n",
        "    result[i,2] = train_time"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch =  0 auc =  0.9629691102756893\n",
            "epoch =  1 auc =  0.9634850250626568\n",
            "epoch =  2 auc =  0.9364810463659148\n",
            "epoch =  3 auc =  0.9608318609022556\n",
            "epoch =  4 auc =  0.9693107142857142\n",
            "epoch =  5 auc =  0.9008003446115288\n",
            "epoch =  6 auc =  0.9479872180451129\n",
            "epoch =  7 auc =  0.9777182957393483\n",
            "epoch =  8 auc =  0.956848088972431\n",
            "epoch =  9 auc =  0.9107729949874687\n",
            "epoch =  10 auc =  0.945560902255639\n",
            "epoch =  11 auc =  0.9597188596491227\n",
            "epoch =  12 auc =  0.9141996553884713\n",
            "epoch =  13 auc =  0.9609213032581454\n",
            "epoch =  14 auc =  0.9332078947368421\n",
            "epoch =  15 auc =  0.9300077067669174\n",
            "epoch =  16 auc =  0.9568131578947369\n",
            "epoch =  17 auc =  0.9167437969924812\n",
            "epoch =  18 auc =  0.9489448934837093\n",
            "epoch =  19 auc =  0.9268577380952382\n",
            "epoch =  20 auc =  0.927665820802005\n",
            "epoch =  21 auc =  0.9503483082706765\n",
            "epoch =  22 auc =  0.9395378446115288\n",
            "epoch =  23 auc =  0.9234465538847118\n",
            "epoch =  24 auc =  0.9551843358395989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZdfa3nkAdI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41a58d7-fb91-41a0-a640-279e80f12528"
      },
      "source": [
        "np.mean(result, 0)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.        ,  0.94305454, 14.97168523])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKeMkT3GAfVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84857067-394e-4547-990d-86c35dd64fcd"
      },
      "source": [
        "np.std(result, 0)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.21110255, 0.01982106, 0.38492927])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA6iHMQkAhEf"
      },
      "source": [
        "nu = 0.3\n",
        "x_train_mix, y_train_mix = gernate_data(6000, nu, 16, range_ = 10, multi = 15, size = size)\n",
        "x_test_mix, y_test_mix = gernate_data(10000, nu, 16,range_ = 10, multi = 15, size = size)\n",
        "n_samples = len(x_train_mix)\n",
        "\n",
        "\n",
        "batch_size = 2000\n",
        "train_buf = x_train_mix.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_mix, y_train_mix))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=train_buf)\n",
        "train_dataset = train_dataset.batch(batch_size)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si-vDYNNmg2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10731c7-b4e9-4968-ce04-faa44904f5eb"
      },
      "source": [
        "result = np.zeros((25, 3))\n",
        "warm_up_n_epochs = 10\n",
        "for i in range(25):\n",
        "    pre_time = time.time()\n",
        "    ae_model = make_ae_model()\n",
        "    ae_model.compile(optimizer=\"Adam\", loss=\"mse\")\n",
        "    ae_model.fit(x_train_mix, x_train_mix, epochs = 30, verbose = 0)\n",
        "    ## 訓練 SVDD\n",
        "    binary_model = make_model(ae_model)\n",
        "    binary = train_classfication(binary_model, train_dataset, nu)\n",
        "    binary.train(x_train_mix)\n",
        "    auc  = binary.test_result(x_test_mix, y_test_mix)\n",
        "    train_time = time.time() - pre_time\n",
        "    print('epoch = ', i, 'auc = ', auc)\n",
        "    result[i,0] = i\n",
        "    result[i,1] = auc\n",
        "    result[i,2] = train_time"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch =  0 auc =  0.8836340476190475\n",
            "epoch =  1 auc =  0.9520894047619047\n",
            "epoch =  2 auc =  0.957779380952381\n",
            "epoch =  3 auc =  0.9393547380952381\n",
            "epoch =  4 auc =  0.9623134523809523\n",
            "epoch =  5 auc =  0.9596931666666667\n",
            "epoch =  6 auc =  0.9455563095238095\n",
            "epoch =  7 auc =  0.9410514523809523\n",
            "epoch =  8 auc =  0.9296282142857144\n",
            "epoch =  9 auc =  0.9435848095238095\n",
            "epoch =  10 auc =  0.9361448095238095\n",
            "epoch =  11 auc =  0.9669114285714285\n",
            "epoch =  12 auc =  0.9469449523809523\n",
            "epoch =  13 auc =  0.9469300714285713\n",
            "epoch =  14 auc =  0.9426777142857143\n",
            "epoch =  15 auc =  0.9256253333333333\n",
            "epoch =  16 auc =  0.9364204285714286\n",
            "epoch =  17 auc =  0.9644617619047617\n",
            "epoch =  18 auc =  0.9380168095238096\n",
            "epoch =  19 auc =  0.9417813333333334\n",
            "epoch =  20 auc =  0.9408916904761904\n",
            "epoch =  21 auc =  0.9553310000000002\n",
            "epoch =  22 auc =  0.9476690714285714\n",
            "epoch =  23 auc =  0.9235424761904762\n",
            "epoch =  24 auc =  0.9481223333333332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbVqjLqMmg2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffcb8d2-da58-4141-8cb9-ca3d97061033"
      },
      "source": [
        "np.mean(result, 0)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.        ,  0.94304625, 15.08144714])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1adJ_y-9mg20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1c5764-3280-4e76-fdca-b1bd3ad917a6"
      },
      "source": [
        "np.std(result, 0)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.21110255, 0.01642539, 0.44931136])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbsSQ6WUmg22"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}